{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pythonwebinar.png\" style=\"width:650px\">\n",
    "\n",
    "### AccelerateAI - Python for Data Science - Notebook 05\n",
    "##### Introduction to Python Language  (Python 3) \n",
    "In this notebook we will cover the following: \n",
    "* 2. Pandas      <br>\n",
    "    - Series\n",
    "    - Data Frame\n",
    "       - Indexing\n",
    "       - Grouping\n",
    "       - Missing Data\n",
    "       - Merging / Joining\n",
    "       - Data Operations\n",
    "       - Reading CSV/Excel/HTML\n",
    "       - Basic Plotting\n",
    "\n",
    "We will cover the following in Notebook 2:\n",
    "* 3. String & Text <br> \n",
    "* 4. Regular Expression <br>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Pandas\n",
    "- Pandas is a Python package providing fast and flexible data structure\n",
    "- It is designed to work with structured, relational or labeled (tabular) data \n",
    "- It has functions for reading, analyzing, cleaning, exploring(plotting), and manipulating data\n",
    "- It works very well with large amount of data for indexing, subsetting, slicing, reshaping and merging\n",
    "- It is also great for working with time series data with functionality for quick filtering and plotting\n",
    "- The name \"Pandas\" has a reference to both \"Panel Data\", and \"Python Data Analysis\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1 Pandas data structures\n",
    "- Pandas has a few important data structures:\n",
    "    - Series: Indexed 1-dimensional array holding data of any type (like a column in a table) \n",
    "    - DataFrame: Indexed 2-dimensional data structre (a table with rows and columns)\n",
    "    - Datetime / TimeStamp: also an important data structure for working with dates\n",
    "<br><br>\n",
    "- Other data structures like pandas array, strings etc are not in common use.\n",
    "- Panel data a 3 dimesional data structure for storing panel data, is now deprecated and no longer in use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2.1.1 Pandas Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas \n",
    "import numpy as np\n",
    "\n",
    "##import pandas as pd                       # remove comments and execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a series from list\n",
    "a = [1, 7, 2, 5,9]\n",
    "myseries = pd.Series()                      # convert a to Series\n",
    "\n",
    "print(myseries)                             #notice the index printed with the values, along with data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specifying the index \n",
    "myserwithind = pd.Series(a, [\"a\", \"b\", \"c\", \"b\", \"e\"])\n",
    "print(myserwithind) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a series from dictionary\n",
    "calories = {\"day1\": 420, \"day2\": 380, \"day3\": 390}\n",
    "\n",
    "mydiet = (calories)                       # Create a series\n",
    "\n",
    "print(mydiet)                             #where do the keys go? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naming the series attributes \n",
    "\n",
    "fruitprice = {'apples': 200, 'kiwi': 300, 'oranges': 70, 'cherries': 500, 'banana':30, 'guava':55}\n",
    "mySeries = pd.Series(fruitprice)\n",
    "\n",
    "#mySeries.name = 'March Fruit Prices'                 #name is the sweetest sound for every individual!\n",
    "#mySeries.index.name = 'Fruit'                        #why should index be left behind?\n",
    "\n",
    "print(mySeries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the dimension\n",
    "mySeries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the num of elements\n",
    "mySeries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#indexing using list style\n",
    "mySeries[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mySeries[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#indexing using index value\n",
    "mySeries[['kiwi', 'oranges']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#which is the most expensive fruit?\n",
    "mySeries.                                               # use idxmax() - argmax() is depreciated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#which are the two cheapest fruits\n",
    "mySeries.nsmallest(n=?, keep='last')                    # similarly nlargest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistics \n",
    "print (\"Avg Price:\",mySeries.mean())\n",
    "print (\"Median Price:\",mySeries.())\n",
    "print(\"Std deviation:\", mySeries.())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data distribution\n",
    "mySeries.() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort the series by value\n",
    "mySeries.sort_values()                                  # why such a long name? because there are more than one way to sort!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort the series by index\n",
    "mySeries.sort_index()                                   # alphabetical order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting an element in a pandas series \n",
    "print(mySeries[1])\n",
    "print(mySeries['kiwi'])\n",
    "print(mySeries.kiwi)\n",
    "print(mySeries.loc['kiwi'])\n",
    "print(mySeries.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#price of kiwi increases \n",
    "mySeries['kiwi'] = #350                              \n",
    "print(mySeries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching using index \n",
    "'apples' in mySeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding two series \n",
    "basket1 = pd.Series({'apples': 5, 'kiwi': 10, 'oranges': 7, 'cherries': 50})\n",
    "basket2 = pd.Series({'apples': 6, 'pineapple': 2, 'oranges': 6, 'banana': 12})\n",
    "\n",
    "total = basket1 + \n",
    "print(total)                                          # What would be the output? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Appending two series \n",
    "basket1.append()                                      # Now? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basket1                                               # Does this change basket1? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basket1.plot()                                        # plotting a series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2.1.2 DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dataframe from dictionary\n",
    "df1 = pd.DataFrame(\n",
    "    {\n",
    "        \"A\": [1.0,2.3,3.4,4.3],\n",
    "        \"B\": pd.Timestamp(\"20130102\"),\n",
    "        \"C\": pd.Series(1, index=list(range(4)), dtype=\"float32\"),\n",
    "        \"D\": np.array([3] * 4, dtype=\"int32\"),\n",
    "        \"E\": pd.Categorical([\"test\", \"train\", \"test\", \"train\"]),\n",
    "        \"F\": pd.Categorical([\"spam\",\"ham\"]*2)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1.shape                                   #(rows , columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick statistic summary of the data (numerical)\n",
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick look - random sample\n",
    "df1.sample(?)                              #head(n) and tail(n) also works as intended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2.1.2.1 Row and Column Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selection of rows\n",
    "df1[0:2]                                  #list style indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selection of rows\n",
    "df1.iloc[0:2,]                             #optimized and recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selection of columns - using names\n",
    "df1.loc[:, [\"A\", \"B\"]]                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selection using numerical position \n",
    "df1.iloc[0:3, 1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional selection using a single column\n",
    "df1[df1.A>3.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query function \n",
    "df1.('E == \"test\"')                                # equivaluent to df1[df1['E'] == \"test\"]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding a new column\n",
    "df1[\"G\"] = [\"one\", \"two\", \"three\", \"four\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[df1.G.isin([\"two\", \"four\"])]                   #.isin() for selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping a column\n",
    "df1.drop('G', axis=1 )                             #inplace=True will make changes to existing dataframe              \n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting values \n",
    "import numpy as np\n",
    "df1.loc[:, \"D\"] = np.arange(10,14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.2.2 Grouping Data \n",
    "- this function takes several params and returns DataFrameGroupBy object that contains information about the groups.\n",
    "- we can use groupby() with the combination of sum(), pivot(), transform(), aggregate() and many more methods.\n",
    "- Syntax of DataFrame.groupby()<br>\n",
    "    DataFrame.groupby(by=None, axis=0, level=None, as_index=True,\n",
    "    sort=True, group_keys=True, squeeze=<no_default>,      <br>\n",
    "    observed=False, dropna=True)                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouping data\n",
    "df = pd.DataFrame({'Company':['GOOG','GOOG','MSFT','MSFT','FB','FB'],\n",
    "                   'Month':['Jan','Feb','Jan','Feb','Jan','Feb'],\n",
    "                   'Sales':[200,120,340,124,243,350]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average sales per company\n",
    "df.groupby(\"\").mean()               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total sales per month\n",
    "df.groupby(\"Month\").  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group by a numerical value(bins) calculate a statistic\n",
    "s_groups = pd.cut(df['Sales'], bins=[100, 200, 300, np.inf])\n",
    "\n",
    "df.groupby().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross tabulation \n",
    "pd.(df.Company, df.Month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.2.3 Dealing with missing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'A':[1,2,np.nan,3],'B':[5,np.nan, np.nan,7],'C':[1,2,3,4]}\n",
    "df = pd.DataFrame(d)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows with NaN value\n",
    "df.dropna() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drops cols with null values with given threshold (atleast n non-NaNs for the column to survive)\n",
    "df.dropna(axis=1, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill NaN with a user specified value\n",
    "df_new = df.fillna(value=\"99\")                              #to change the df use inplace=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill NaN with different value for different column\n",
    "\n",
    "colfill = {\"A\": -99, \"B\": 99, \"C\": 999}\n",
    "df.fillna(value=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill NaN with forward fill method - last valid number\n",
    "df.fillna(method='')                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill NaN with backfill fill method - next valid number\n",
    "df.fillna(method='')                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['A'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean imputation\n",
    "df.fillna(value= df['A']. ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.2.4 Merging  & Joining Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = {\"Id\": ['I01', 'I02', 'I03', 'I04','I05'],\n",
    "     \"Name\":['Aamir', 'Salman', 'Shahrukh', 'Akshay', 'Hrithik'], \n",
    "      \"Age\":[45, 54, 55, 56, 44],} \n",
    "\n",
    "d2 = {\"Id\": ['I02', 'I01', 'I04', 'I03'],\n",
    " \"Address\":[\"Delhi\", \"Gurgaon\", \"Noida\", \"Pune\"], \n",
    " \"Qualification\":[\"Btech\", \"B.A\", \"Bcom\", \"B.hons\"]}\n",
    "\n",
    "df1=pd.DataFrame(d1)\n",
    "df2=pd.DataFrame(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat() is used for combining Data Frames across rows or columns.\n",
    "pd.concat([df1,df2], axis=0, sort=False)                     #ignore_index=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat() is used for combining Data Frames across rows or columns.\n",
    "pd.concat([df1,df2], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.append(df2, sort=False)                  #same as concat(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge() is used for combining data on common columns or indices.\n",
    "df1.merge(df2)                                    #Inner Join - automatically on \"Id\" - common rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1,df2,left_on=\"Id\",right_on=\"Id\",how='inner')        #if column names are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1,df2,how='left')                                   #Left Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1,df2,how='outer')                                   #Outer Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join() is used for combining data on index.\n",
    "df1.join(df2, lsuffix='_l', rsuffix='_r')                  #Same column get renamed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.2.5 Operations on Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count of each column\n",
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats for numeric cols\n",
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique values\n",
    "df2[\"Address\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply a function to each row\n",
    "df1[\"Age\"].apply(lambda x: x/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.sort_values('Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.2.6 Data Input & Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading csv file into a DataFrame\n",
    "netflix_df = pd.(\"netflix_subscription_fee.csv\")\n",
    "netflix_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading an excel file into a DataFrame\n",
    "insurance_df = pd.(\"insurance_data.xlsx\",sheet_name=0, parse_dates=True)\n",
    "insurance_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_df.InsuredValue.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html5lib\n",
    "#Read HTML tables into a list of DataFrame objects.\n",
    "data = pd.('https://www.fdic.gov/resources/resolutions/bank-failures/failed-bank-list/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading a json file \n",
    "iris_df = pd.(\"https://raw.githubusercontent.com/domoritz/maps/master/data/iris.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing to a csv file\n",
    "iris_df.(\"iris.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.2.7 Basic Plots \n",
    "- Pandas uses the plot() method to create diagrams.\n",
    "- Pyplot, a submodule of the Matplotlib library can be used to visualize the diagram on the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read motor trends cars data from the web   \n",
    "data = pd.read_html(\"https://gist.github.com/seankross/a412dfbd88b3db70b74b\")\n",
    "mtcars_df = data[0]\n",
    "mtcars_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot\n",
    "mtcars_df.plot(kind = 'scatter', x = 'disp', y = 'hp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram\n",
    "mtcars_df[\"mpg\"].plot(kind = 'hist', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### That's it folks !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
